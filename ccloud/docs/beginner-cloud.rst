.. _ccloud-cli-tutorial:

Tutorial: |ccloud| CLI
=======================

Overview
--------

This tutorial shows you how to use the `Confluent Cloud CLI
<https://docs.confluent.io/ccloud-cli/current/install.html>`__ to interact with
your `Confluent Cloud <https://confluent.cloud/login>`__ cluster. It uses real
resources in |ccloud|, and it creates and deletes topics, service accounts,
credentials, and ACLs. Following the workflow in this tutorial, you accomplish
the following steps:

-  `Create a new Confluent Cloud environment`_
-  `Create a new Confluent Cloud cluster`_
-  `Create a new API key/secret pair for user`_
-  `Produce and consume records with Confluent Cloud CLI`_
-  `Create a new service account with an API key/secret pair`_
-  `Run a Java producer without ACLs`_
-  `Run a Java producer with ACLs`_
-  `Run a Java producer with a prefixed ACL`_
-  `Run a fully managed Confluent Cloud connector`_
-  `Run a Java consumer with a Wildcard ACL`_
-  `Monitor producers and consumers`_
-  `Clean up Confluent Cloud resources`_

Prerequisites
-------------

-  Access to `Confluent Cloud <https://confluent.cloud/login>`__.

-  Local `install of Confluent Cloud CLI
   <https://docs.confluent.io/ccloud-cli/current/install.html>`__ (v1.21.0 or later)

-  .. include:: ../../ccloud/docs/includes/prereq_timeout.rst

-  `mvn <https://maven.apache.org/install.html>`__ installed on your host

-  `jq <https://github.com/stedolan/jq/wiki/Installation>`__ installed on your host

-  `docker <https://docs.docker.com/get-docker/>`__ installed on your host


Cost to Run Tutorial
--------------------

Caution
~~~~~~~

.. include:: includes/ccloud-examples-caution.rst

|ccloud| Promo Code
~~~~~~~~~~~~~~~~~~~

.. include:: includes/ccloud-examples-promo-code.rst

Run Tutorial
------------

Start
~~~~~

#. Log in to the |ccloud| CLI:

   .. code-block:: bash

      ccloud login --save

   The ``--save`` flag will save your |ccloud| login credentials to the
   ``~/.netrc`` file.


#. Clone the `confluentinc/examples <https://github.com/confluentinc/examples>`__ GitHub repository.

   .. code-block:: bash

       git clone https://github.com/confluentinc/examples.git

#. Navigate to the ``examples/ccloud/beginner-cloud/`` directory and switch to
   the |cp| release branch:

   .. codewithvars:: bash

       cd examples/ccloud/beginner-cloud/
       git checkout |release_post_branch|

#. If you want to manually step through the tutorial, which is advised for new
   users who want to gain familiarity with |ccloud| CLI, skip ahead to the next
   section. Alternatively, you can run the full tutorial end-to-end with the
   :devx-examples:`start.sh script|ccloud/beginner-cloud/start.sh`, which
   automates all the steps in the tutorial:

   .. code-block:: bash

         ./start.sh

Create a new Confluent Cloud environment
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following command to create a new |ccloud| environment
   ``ccloud-stack-000000-beginner-cli``:

   .. code-block:: bash

      ccloud environment create ccloud-stack-000000-beginner-cli -o json

#. Verify your output resembles:

   .. code-block:: text

      {
        "id": "env-5qz2q",
        "name": "ccloud-stack-000000-beginner-cli"
      }

   The value of the environment ID, in this case ``env-5qz2q``, may differ in
   your output. In this tutorial, the values for certain variables, including
   your environment ID, |ak| cluster ID, API key, will be unique and will not
   match the output shown.

#. Specify ``env-5qz2q`` as the active environment by running the following
   command:

   .. code-block:: bash

       ccloud environment use env-5qz2q

#. Verify your output resembles:

   .. code-block:: text

      Now using "env-5qz2q" as the default (active) environment.


Create a new Confluent Cloud cluster
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following command to create a new |ccloud| cluster
   ``demo-kafka-cluster``. It takes up to 5 minutes for the |ak| cluster to be
   ready.

   .. code-block:: bash

      ccloud kafka cluster create demo-kafka-cluster --cloud aws --region us-west-2

   .. tip::

      You may choose any provider or region from the list generated by running
      ``ccloud kafka region list``.

#. Verify your output resembles:

   .. code-block:: text

      +--------------+---------------------------------------------------------+
      | Id           | lkc-x6m01                                               |
      | Name         | demo-kafka-cluster                                      |
      | Type         | BASIC                                                   |
      | Ingress      |                                                     100 |
      | Egress       |                                                     100 |
      | Storage      |                                                    5000 |
      | Provider     | aws                                                     |
      | Availability | single-zone                                             |
      | Region       | us-west-2                                               |
      | Status       | UP                                                      |
      | Endpoint     | SASL_SSL://pkc-4kgmg.us-west-2.aws.confluent.cloud:9092 |
      | ApiEndpoint  | https://pkac-ldgj1.us-west-2.aws.confluent.cloud        |
      +--------------+---------------------------------------------------------+

   The value of the |ak| cluster ID, in this case ``lkc-x6m01``, and |ak|
   cluster endpoint, in this case
   ``pkc-4kgmg.us-west-2.aws.confluent.cloud:9092``, may differ in your output.

#. Specify ``lkc-x6m01`` as the active |ak| cluster by running the following
   command:

   .. code-block:: bash

      ccloud kafka cluster use lkc-x6m01

#. Verify your output resembles:

   .. code-block:: text

       Set Kafka cluster "lkc-x6m01" as the active cluster for environment "env-5qz2".


Create a new API key/secret pair for user
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following command to create a user API key/secret pair for your |ak|
   cluster ``lkc-x6m01``:

   .. code-block:: bash

      ccloud api-key create --description "Demo credentials" --resource lkc-x6m01 -o json

#. Verify your output resembles:

   .. code-block:: text

      {
         "key": "QX7X4VA4DFJTTOIA",
         "secret": "fjcDDyr0Nm84zZr77ku/AQqCKQOOmb35Ql68HQnb60VuU+xLKiu/n2UNQ0WYXp/D"
      }

   The value of the API key, in this case ``QX7X4VA4DFJTTOIA``, and API secret,
   in this case
   ``fjcDDyr0Nm84zZr77ku/AQqCKQOOmb35Ql68HQnb60VuU+xLKiu/n2UNQ0WYXp/D`` may
   differ in your output.

#. Specify the API key ``QX7X4VA4DFJTTOIA`` for the |ak| cluster ``lkc-x6m01``:

   .. code-block:: bash

      ccloud api-key use QX7X4VA4DFJTTOIA --resource lkc-x6m01

   Your output should resemble:

   .. code-block:: text

      Set the API Key "QX7X4VA4DFJTTOIA" as the active API key for "lkc-x6m01".


Produce and consume records with Confluent Cloud CLI
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following command to create a new |ak| topic ``demo-topic-1``:

   .. code-block:: bash

      ccloud kafka topic create demo-topic-1

#. Start producing to this topic ``demo-topic-1`` by running the following command:

   .. code-block:: bash

      ccloud kafka topic produce demo-topic-1

#. The CLI waits for you to type data at the prompt, so type a few characters each on a new line. For example, type the numbers 1 through 5:

   .. code-block:: bash

      1
      2
      3
      4
      5

#. Type ``<CTRL-C>`` when you are finished.

#. Run the following command to consume messages from topic ``demo-topic-1``.
   The flag ``-b`` allows the consumer to read from the beginning of the topic.

   .. code-block:: bash

      ccloud kafka topic consume demo-topic-1 -b

#. Verify your output resembles the following. It is expected to be out of order because of round-robin partitioner:

   .. code-block:: text

      Starting Kafka Consumer. ^C or ^D to exit
      1
      3
      5
      2
      4

#. Type ``CTRL-C`` to stop the consumer.


Create a new service account with an API key/secret pair
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following command to create a new service account:

   .. code-block:: bash

      ccloud service-account create demo-app-3288 --description demo-app-3288 -o json

#. Verify your output resembles:

   .. code-block:: text

      {
         "id": 104349,
         "name": "demo-app-3288",
         "description": "demo-app-3288"
      }

   The value of the service account ID, in this case ``104349``, may differ in
   your output.

#. Create an API key and secret for the service account ``104349`` for the |ak|
   cluster ``lkc-x6m01`` by running the following command:

   .. code-block:: bash

      ccloud api-key create --service-account 104349 --resource lkc-x6m01 -o json

#. Verify your output resembles:

   .. code-block:: text

      {
        "key": "ESN5FSNDHOFFSUEV",
        "secret": "nzBEyC1k7zfLvVON3vhBMQrNRjJR7pdMc2WLVyyPscBhYHkMwP6VpPVDTqhctamB"
      }

   The value of the service account's API key, in this case
   ``ESN5FSNDHOFFSUEV``, and API secret, in this case
   ``nzBEyC1k7zfLvVON3vhBMQrNRjJR7pdMc2WLVyyPscBhYHkMwP6VpPVDTqhctamB``, may
   differ in your output.

#. Create a local configuration file ``/tmp/client.config`` with |ccloud|
   connection information using the newly created |ak| cluster and the API key
   and secret for the service account. Substitute your values for the bootstrap
   server and credentials just created.

   .. code-block:: text

       sasl.mechanism=PLAIN
       security.protocol=SASL_SSL
       bootstrap.servers=pkc-4kgmg.us-west-2.aws.confluent.cloud:9092
       sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='ESN5FSNDHOFFSUEV' password='nzBEyC1k7zfLvVON3vhBMQrNRjJR7pdMc2WLVyyPscBhYHkMwP6VpPVDTqhctamB';

#. Wait about 90 seconds for the |ccloud| cluster to be ready and for the
   service account credentials to propagate.


Run a Java producer without ACLs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. By default, no ACLs are configured for the service account, which means the
   service account has no access to any |ccloud| resources. Run the following
   command to verify no ACLs are configured:

   .. code-block:: bash

      ccloud kafka acl list --service-account 104349

   Your output should resemble:

   .. code-block:: text

        ServiceAccountId | Permission | Operation | Resource | Name | Type
      +------------------+------------+-----------+----------+------+------+

#. Compile the Java project at :devx-examples:`clients/cloud/java|clients/cloud/java/`

   .. code-block:: bash

      mvn  -f ../../clients/cloud/java/pom.xml compile

#. Run a Java producer to ``demo-topic-1`` before configuring ACLs (expected
   to fail). Note that you pass in an argument to ``/tmp/client.config`` which
   has the |ccloud| connection information:

   .. code-block:: bash

      mvn -q -f ../../clients/cloud/java/pom.xml exec:java -Dexec.mainClass="io.confluent.examples.clients.cloud.ProducerExample" -Dexec.args="/tmp/client.config demo-topic-1" -Dlog4j.configuration=file:log4j.properties > /tmp/log.1 2>&1

#. Verify you see ``org.apache.kafka.common.errors.TopicAuthorizationException``
   in the log file ``/tmp/log.1`` as shown in the following example (expected
   because there are no ACLs to allow this client application):

   .. code-block:: text

       [ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2.1:java (default-cli) on project clients-example: An exception occured while executing the Java class. null: InvocationTargetException: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TopicAuthorizationException: Authorization failed. -> [Help 1]

Run a Java producer with ACLs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following commands to create ACLs for the service account:

   .. code-block:: bash

      ccloud kafka acl create --allow --service-account 104349 --operation CREATE --topic demo-topic-1
      ccloud kafka acl create --allow --service-account 104349 --operation WRITE --topic demo-topic-1

#. Verify your output resembles:

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource |     Name     |  Type
       +------------------+------------+-----------+----------+--------------+---------+
         User:104349      | ALLOW      | CREATE    | TOPIC    | demo-topic-1 | LITERAL

         ServiceAccountId | Permission | Operation | Resource |     Name     |  Type
       +------------------+------------+-----------+----------+--------------+---------+
         User:104349      | ALLOW      | WRITE     | TOPIC    | demo-topic-1 | LITERAL

#. Run the following command and verify the ACLs were configured:

   .. code-block:: bash

      ccloud kafka acl list --service-account 104349

   Your output should resemble below. Observe that the ACL Type is ``LITERAL``.

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource |     Name     |  Type
       +------------------+------------+-----------+----------+--------------+---------+
         User:104349      | ALLOW      | CREATE    | TOPIC    | demo-topic-1 | LITERAL
         User:104349      | ALLOW      | WRITE     | TOPIC    | demo-topic-1 | LITERAL

#. Run the Java producer to ``demo-topic-1`` after configuring the ACLs
   (expected to pass):

   .. code-block:: bash

      mvn -q -f ../../clients/cloud/java/pom.xml exec:java -Dexec.mainClass="io.confluent.examples.clients.cloud.ProducerExample" -Dexec.args="/tmp/client.config demo-topic-1" -Dlog4j.configuration=file:log4j.properties > /tmp/log.2 2>&1

#. Verify you see the ``10 messages were produced to topic`` message in the
   log file ``/tmp/log.2`` as shown in the following example:

   .. code-block:: text

         Producing record: alice	{"count":0}
         Producing record: alice	{"count":1}
         Producing record: alice	{"count":2}
         Producing record: alice	{"count":3}
         Producing record: alice	{"count":4}
         Producing record: alice	{"count":5}
         Producing record: alice	{"count":6}
         Producing record: alice	{"count":7}
         Producing record: alice	{"count":8}
         Producing record: alice	{"count":9}
         Produced record to topic demo-topic-1 partition [3] @ offset 0
         Produced record to topic demo-topic-1 partition [3] @ offset 1
         Produced record to topic demo-topic-1 partition [3] @ offset 2
         Produced record to topic demo-topic-1 partition [3] @ offset 3
         Produced record to topic demo-topic-1 partition [3] @ offset 4
         Produced record to topic demo-topic-1 partition [3] @ offset 5
         Produced record to topic demo-topic-1 partition [3] @ offset 6
         Produced record to topic demo-topic-1 partition [3] @ offset 7
         Produced record to topic demo-topic-1 partition [3] @ offset 8
         Produced record to topic demo-topic-1 partition [3] @ offset 9
         10 messages were produced to topic demo-topic-1

#. Delete the ACLs:

   .. code-block:: bash

      ccloud kafka acl delete --allow --service-account 104349 --operation CREATE --topic demo-topic-1
      ccloud kafka acl delete --allow --service-account 104349 --operation WRITE --topic demo-topic-1

   You should see two ``Deleted ACLs.`` messages.


Run a Java producer with a prefixed ACL
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Create a new |ak| topic ``demo-topic-2``:

   .. code-block:: bash

      ccloud kafka topic create demo-topic-2

   Verify you see the ``Created topic "demo-topic-2"`` message.

#. Run the following command to create ACLs for the producer using a prefixed ACL
   which matches any topic that starts with the prefix ``demo-topic``:

   .. code-block:: bash

      ccloud kafka acl create --allow --service-account 104349 --operation CREATE --topic demo-topic --prefix
      ccloud kafka acl create --allow --service-account 104349 --operation WRITE --topic demo-topic --prefix

#. Verify your output resembles:

   .. code-block:: text

      ServiceAccountId | Permission | Operation | Resource |    Name    |   Type
      +------------------+------------+-----------+----------+------------+----------+
      User:104349      | ALLOW      | CREATE    | TOPIC    | demo-topic | PREFIXED

      ServiceAccountId | Permission | Operation | Resource |    Name    |   Type
      +------------------+------------+-----------+----------+------------+----------+
      User:104349      | ALLOW      | WRITE     | TOPIC    | demo-topic | PREFIXED

#. Verify the ACLs were configured by running the following command:

   .. code-block:: bash

      ccloud kafka acl list --service-account 104349

   Your output should resemble below. Observe that the ACL Type is ``PREFIXED``.

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource |    Name    |   Type
       +------------------+------------+-----------+----------+------------+----------+
         User:104349      | ALLOW      | WRITE     | TOPIC    | demo-topic | PREFIXED
         User:104349      | ALLOW      | CREATE    | TOPIC    | demo-topic | PREFIXED

#. Run the Java producer to ``demo-topic-2``, which should match the newly
   created prefixed ACLs.

   .. code-block:: bash

      mvn -q -f ../../clients/cloud/java/pom.xml exec:java -Dexec.mainClass="io.confluent.examples.clients.cloud.ProducerExample" -Dexec.args="/tmp/client.config demo-topic-2" -Dlog4j.configuration=file:log4j.properties > /tmp/log.3 2>&1

#. Verify you see the ``10 messages were produced to topic`` message in the log
   file ``/tmp/log.3`` as shown in the following example:

   .. code-block:: text

      Producing record: alice	{"count":0}
      Producing record: alice	{"count":1}
      Producing record: alice	{"count":2}
      Producing record: alice	{"count":3}
      Producing record: alice	{"count":4}
      Producing record: alice	{"count":5}
      Producing record: alice	{"count":6}
      Producing record: alice	{"count":7}
      Producing record: alice	{"count":8}
      Producing record: alice	{"count":9}
      Produced record to topic demo-topic-2 partition [3] @ offset 0
      Produced record to topic demo-topic-2 partition [3] @ offset 1
      Produced record to topic demo-topic-2 partition [3] @ offset 2
      Produced record to topic demo-topic-2 partition [3] @ offset 3
      Produced record to topic demo-topic-2 partition [3] @ offset 4
      Produced record to topic demo-topic-2 partition [3] @ offset 5
      Produced record to topic demo-topic-2 partition [3] @ offset 6
      Produced record to topic demo-topic-2 partition [3] @ offset 7
      Produced record to topic demo-topic-2 partition [3] @ offset 8
      Produced record to topic demo-topic-2 partition [3] @ offset 9
      10 messages were produced to topic demo-topic-2

#. Run the following commands to delete ACLs:

   .. code-block:: bash

      ccloud kafka acl delete --allow --service-account 104349 --operation CREATE --topic demo-topic --prefix
      ccloud kafka acl delete --allow --service-account 104349 --operation WRITE --topic demo-topic --prefix

   You should see two ``Deleted ACLs.`` messages.


Run a fully managed Confluent Cloud connector
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Create a new |ak| topic ``demo-topic-3``:

   .. code-block:: bash

      ccloud kafka topic create demo-topic-3

   You should see a ``Created topic "demo-topic-3"`` message.

#. Run the following command to allow service account ID ``104349`` to write to
   any topic:

   .. code-block:: bash

      ccloud kafka acl create --allow --service-account 104349 --operation WRITE --topic '*'

#. Verify your output resembles:

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource | Name |  Type
       +------------------+------------+-----------+----------+------+---------+
         User:104349      | ALLOW      | WRITE     | TOPIC    | *    | LITERAL

#. Verify the ACLs were configured by running the following command:

   .. code-block:: bash

      ccloud kafka acl list --service-account 104349

   Your output should resemble:

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource |  Name   |  Type
       +------------------+------------+-----------+----------+---------+---------+
         User:104349      | ALLOW      | WRITE     | TOPIC    | *       | LITERAL

#. Create a local configuration file
   :devx-examples:`datagen_ccloud_pageviews.json|ccloud/beginner-cloud/datagen_ccloud_pageviews.json`
   with |ccloud| connection information. Substitute your API key and secret for the service account,
   in the ``kafka.api.key`` and ``kafka.api.secret`` fields. See below for an example:

   .. literalinclude:: ../beginner-cloud/datagen_ccloud_pageviews.json

#. Create a managed connector in Confluent Cloud with the configuration file you made in the
   previous step using the following commands:

   .. code-block:: text

      ccloud connector create --config datagen_ccloud_pageviews.json

   Your output should resemble:

   .. code-block:: text

      Created connector datagen_ccloud_pageviews lcc-zno83

#. The connector may take up to 5 minutes to provision. Run the following command to check the connector status

   .. code-block:: bash

      ccloud connector list

   Your output should resemble the following:

   .. code-block:: text

           ID     |           Name            |    Status    |  Type  | Trace
      +-----------+---------------------------+--------------+--------+-------+
        lcc-zno83 | datagen_ccloud_pageviews  | PROVISIONING | source |

   When the ``Status`` is ``RUNNING`` you may move on to the next step.

Run a Java consumer with a Wildcard ACL
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Create ACLs for the consumer using a wildcard by running the following
   commands:

   .. code-block:: bash

      ccloud kafka acl create --allow --service-account 104349 --operation READ --consumer-group demo-beginner-cloud-1
      ccloud kafka acl create --allow --service-account 104349 --operation READ --topic '*'

#. Verify your output resembles:

   .. code-block:: text

        ServiceAccountId | Permission | Operation | Resource |         Name          |  Type
      +------------------+------------+-----------+----------+-----------------------+---------+
        User:104349      | ALLOW      | READ      | GROUP    | demo-beginner-cloud-1 | LITERAL

        ServiceAccountId | Permission | Operation | Resource | Name |  Type
      +------------------+------------+-----------+----------+------+---------+
        User:104349      | ALLOW      | READ      | TOPIC    | *    | LITERAL


#. Verify the ACLs were configured by running the following command:

   .. code-block:: bash

      ccloud kafka acl list --service-account 104349

   Your output should resemble:

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource |         Name          |  Type
       +------------------+------------+-----------+----------+-----------------------+---------+
         User:104349      | ALLOW      | WRITE     | TOPIC    | *                     | LITERAL
         User:104349      | ALLOW      | READ      | TOPIC    | *                     | LITERAL
         User:104349      | ALLOW      | READ      | GROUP    | demo-beginner-cloud-1 | LITERAL


#. Run the Java consumer from ``demo-topic-3`` which is populated by
   the datagen_ccloud_pageviews connector, and wait 15 seconds for it to complete.

   .. code-block:: bash

      timeout 15s mvn -q -f ../../clients/cloud/java/pom.xml exec:java -Dexec.mainClass="io.confluent.examples.clients.cloud.ConsumerExamplePageviews" -Dexec.args="/tmp/client.config demo-topic-3" -Dlog4j.configuration=file:log4j.properties > /tmp/log.4 2>&1

#. Verify you see ``Consumed record with`` messages in the log file
   ``/tmp/log.4`` as shown in the following example:

   .. code-block:: text

      Consumed record with key 71 and value {"viewtime":71,"userid":"User_6","pageid":"Page_11"}
      Consumed record with key 51 and value {"viewtime":51,"userid":"User_7","pageid":"Page_24"}
      Consumed record with key 31 and value {"viewtime":31,"userid":"User_7","pageid":"Page_68"}
      Consumed record with key 81 and value {"viewtime":81,"userid":"User_5","pageid":"Page_25"}
      Consumed record with key 41 and value {"viewtime":41,"userid":"User_2","pageid":"Page_88"}
      Consumed record with key 91 and value {"viewtime":91,"userid":"User_2","pageid":"Page_74"}

#. Delete the ACLs by running the following command:

   .. code-block:: bash

      ccloud kafka acl delete --allow --service-account 104349 --operation READ --consumer-group demo-beginner-cloud-1
      ccloud kafka acl delete --allow --service-account 104349 --operation READ --topic '*'

   You should see two ``Deleted ACLs.`` messages.

#. Stop Docker:

   .. code-block:: bash

        docker-compose down

#. Verify you see the following output:

   .. code-block:: text

      Stopping connect-cloud ... done
      Removing connect-cloud ... done
      Removing network beginner-cloud_default

#. Delete the ACLs:

   .. code-block:: bash

      ccloud kafka acl delete --allow --service-account 104349 --operation WRITE --topic '*'

   You should see a ``Deleted ACLs.`` message after running each of the previous
   commands.


Monitor producers and consumers
-------------------------------

Using Confluent Cloud has the advantage of circumventing the trials and tribulations of monitoring
a Kafka cluster but you still need to monitor your client applications. Your success in Confluent
Cloud largely depends on how well your applications are performing. Monitoring your client
applications will give you insights on how to fine tune your producers and consumers, when to scale
your Confluent Cloud cluster, what might be going wrong and how to resolve the problem.

This module will cover how to setup a time-series database (Prometheus) populated with data from the
Confluent Cloud Metrics API and client metrics from a locally running Java consumer and producer,
along with how to setup a data visualization tool (Grafana). After the initial setup, a set of use
cases.

Monitoring Container Setup
**************************


First we will create a base client container and set all the necessary acls to allow our clients to read, write, and create streams.

#. Create `localbuild:client` docker image:

   .. code-block:: bash

      docker build -t localbuild:client .

   This image caches Kafka client dependencies, so that they won't need to be pulled each time we start a client container.

#. Run the following commands to create ACLs for the service account:

   .. code-block:: bash

      ccloud kafka acl create --allow --service-account 104349 --operation CREATE --topic demo-topic-4
      ccloud kafka acl create --allow --service-account 104349 --operation WRITE --topic demo-topic-4
      ccloud kafka acl create --allow --service-account 104349 --operation READ --topic demo-topic-4
      ccloud kafka acl create --allow --service-account 104349 --operation READ  --consumer-group demo-consumer-1


Next we will bring up our monitoring services and client applications.

#. Prior to starting any docker containers, dreate an api-key for the ``cloud`` resource with the command below. The
   `ccloud-exporter <https://github.com/Dabz/ccloudexporter/blob/master/README.md>`_ will use the
   key and secret to authenticate to |ccloud|. ``ccloud-exporter`` queries the
   `Confluent Metrics API <https://docs.confluent.io/cloud/current/monitoring/metrics-api.html>`_
   for metrics about your Confluent Cloud deployment and displays them in a Prometheus scrapable
   webpage.

   .. code-block:: bash

      ccloud api-key create --resource cloud --description "ccloud-exporter" -o json

   Verify your output resembles:

   .. code-block:: text

      {
        "key": "LUFEIWBMYXD2AMN5",
        "secret": "yad2iQkA9zxGvGYU1dmk+wiFJUNktQ3BtcRV9MrspaYhS9Z8g9ulZ7yhXtkRNNLd"
      }

   The value of the API key, in this case ``LUFEIWBMYXD2AMN5``, and API secret, in this case
   ``yad2iQkA9zxGvGYU1dmk+wiFJUNktQ3BtcRV9MrspaYhS9Z8g9ulZ7yhXtkRNNLd``, may differ in your output.

#. Create a ``.env`` file to mimic the following:

   .. code-block:: text

      CCLOUD_API_KEY=LUFEIWBMYXD2AMN5
      CCLOUD_API_SECRET=yad2iQkA9zxGvGYU1dmk+wiFJUNktQ3BtcRV9MrspaYhS9Z8g9ulZ7yhXtkRNNLd"
      CCLOUD_CLUSTER=lkc-x6m01

   This ``.env`` file will be used by the ``ccloud-exporter`` container.

#. Start up Prometheus, Grafana, a ``ccloud-exporter``, and a ``node-exporter`` by running:

   .. code-block:: bash

      docker-compose up -d

Producer or Consumer Client Use Cases
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Confluent Cloud offers different cluster types, each with its own `usage limits <https://docs.confluent.io/cloud/current/clusters/cluster-types.html#basic-clusters>`__. This demo assumes
you are running on a "basic" or "standard" cluster; both have similar limitations. Limits are
important to be cognizant of, otherwise you will find client requests getting throttled or denied.
If you are bumping up against your limits, it might be time to consider upgrading your cluster to a different type.

The dashboard and use cases below are powered by Metrics API data.

|Confluent Cloud Dashboard|

It is unrealistic to instruct you to hit cloud limits in this demo, instead the following will walk
you through where to look in this dashboard if you are experiencing a problem.

Client unable to create a connection
*************************************
There are a few reasons this could happen. Looking solely from a Confluent Cloud limitation perspective, it
is possible you have hit a limit on the number of requests you are allowed to send or total
number of active connections.

#. Open `Grafana <localhost:3000>`__ and use the username `admin` and password `password` to login

#. Navigate to the `Confluent Cloud` dashboard.

#. Check the `Requests (rate)` and the `Active connections` panels.

   |Confluent Cloud Panel|

   These panels will turn yellow when you have hit 80% utilization of a resource and red when you have hit 90% utilization of a resource.


Producer Client Use Cases
~~~~~~~~~~~~~~~~~~~~~~~~~


Consumer Client Use Cases
~~~~~~~~~~~~~~~~~~~~~~~~~


Teardown
~~~~~~~~~

#. Tear down monitoring containers by typing ``docker-compose down`` into the CLI.


Troubleshoot Monitoring
~~~~~~~~~~~~~~~~~~~~~~~

#. Data isn't showing up.

   Navigate to the Prometheus Targets page at `localhost:9090/targets <localhost:9090/targets>`__.

   |Prometheus Targets Unknown|

   This page will show you if Prometheus is scraping the targets you have created.


Clean up Confluent Cloud resources
----------------------------------

#. Complete the following steps to delete the managed connector:

   a. Find the connector ID:
      
      .. code-block:: bash

         ccloud connector list
	 
      Which should display a something similar to below. Locate your connector ID, in this case the connector ID is ``lcc-zno83``.

      .. code-block:: text

              ID     |           Name           | Status  |  Type  | Trace
         +-----------+--------------------------+---------+--------+-------+
           lcc-zno83 | datagen_ccloud_pageviews | RUNNING | source |


   b. Delete the connector, referencing the connector ID from the previous step:
      
      .. code-block:: bash
		      
	 ccloud connector delete lcc-zno83
	 
      You should see: ``Deleted connector "lcc-zno83".``.

#. Run the following command to delete the service account:

   .. code-block:: bash

      ccloud service-account delete 104349

#. Complete the following steps to delete all the |ak| topics:

   a. Delete ``demo-topic-1``:

      .. code-block:: bash

         ccloud kafka topic delete demo-topic-1

      You should see: ``Deleted topic "demo-topic-1"``.

   b. Delete ``demo-topic-2``:

      .. code-block:: bash

         ccloud kafka topic delete demo-topic-2

      You should see: ``Deleted topic "demo-topic-2"``.

   c. Delete ``demo-topic-3``:

      .. code-block:: bash

         ccloud kafka topic delete demo-topic-3

      You should see: ``Deleted topic "demo-topic-3"``.

#. Run the following commands to delete the API keys:

   .. code-block:: bash

      ccloud api-key delete ESN5FSNDHOFFSUEV
      ccloud api-key delete QX7X4VA4DFJTTOIA

#. Delete the |ak| cluster:

   .. code-block:: bash

      ccloud kafka cluster delete lkc-x6m01

#. Delete the environment:

   .. code-block:: bash

      ccloud environment delete env-5qz2q

   You should see: ``Deleted environment "env-5qz2q"``.

If the tutorial ends prematurely, you may receive the following error message
when trying to run the example again (``ccloud environment create
ccloud-stack-000000-beginner-cli``):

.. code-block:: text

      Error: 1 error occurred:
         * error creating account: Account name is already in use

      Failed to create environment ccloud-stack-000000-beginner-cli. Please troubleshoot and run again

In this case, run the following script to delete the example’s topics, |ak|
cluster, and environment:

.. code-block:: bash

   ./cleanup.sh


Advanced usage
--------------

The example script provides variables that allow you to alter the default |ak|
cluster name, cloud provider, and region. For example:

.. code-block:: bash

   CLUSTER_NAME=my-demo-cluster CLUSTER_CLOUD=aws CLUSTER_REGION=us-west-2 ./start.sh

Here are the variables and their default values:

.. list-table::
   :widths: 50 50
   :header-rows: 1

   * - Variable
     - Default
   * - ``CLUSTER_NAME``
     - demo-kafka-cluster
   * - ``CLUSTER_CLOUD``
     - aws
   * - ``CLUSTER_REGION``
     - us-west-2


.. |Prometheus Targets Unknown|
   image:: images/prometheus-targets-unknown.png
   :alt: Prometheus Targets Unknown

.. |Prometheus Targets Up|
   image:: images/prometheus-targets-up.png
   :alt: Prometheus Targets Up

.. |Confluent Cloud Dashboard|
   image:: images/confluent-cloud-dashboard.png
   :alt: Confluent Cloud Dashboard


.. |Confluent Cloud Panel|
   image:: images/cloud-panel.png
   :alt: Confluent Cloud Panel

Additional Resources
--------------------

-  See `Developing Client Applications on Confluent Cloud <https://docs.confluent.io/cloud/best-practices/index.html>`__ for a guide to configuring, monitoring, and
   optimizing your |ak| client applications when using |ccloud|.

-  See other :ref:`ccloud-demos-overview`.
